{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efUjvXToG5WF",
        "outputId": "b73b1af6-eb92-4729-af99-18860ee46b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: INSTALLING / IMPORTING PACKAGES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m  DEPRECATION: Building 'emoji' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'emoji'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "STEP 2: LOADING SENTIMENT140 DATASET\n",
            "Total tweets in raw file: 1,600,000\n",
            "Applying light cleaning...\n",
            "After cleaning: 1,599,978 tweets\n",
            "\n",
            "Using 1,599,978 tweets for training/validation/testing\n",
            "\n",
            "Dataset splits BEFORE augmentation:\n",
            "  Train: 1,591,978\n",
            "  Val:   4,000\n",
            "  Test:  4,000\n",
            "\n",
            "Applying targeted augmentation on TRAIN set only...\n",
            "\n",
            "[Augmentation] Negation-based synthetic examples added: 14,284\n",
            "Final TRAIN size after augmentation: 1,606,267\n",
            "\n",
            "Dataset splits AFTER augmentation:\n",
            "  Train: 1,606,267\n",
            "  Val:   4,000\n",
            "  Test:  4,000\n",
            "STEP 3: LOADING MODEL: vinai/bertweet-large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded model: vinai/bertweet-large\n",
            "Model parameters: 355,361,794\n",
            "\n",
            "Creating datasets & dataloaders...\n",
            "\n",
            "Training configuration:\n",
            "  Steps:  75,294\n",
            "  Warmup: 7,529\n",
            "  Epochs: 3\n",
            "  LR:     1e-05\n",
            "  Batch:  32 (x2 accum)\n",
            "STEP 4: TRAINING\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train: Loss=0.2891, F1=0.8717 (87.17%), Acc=0.8738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Val:   Loss=0.2718, F1=0.9306 (93.06%), Acc=0.8702\n",
            "New best model saved (Val F1=0.9306)\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train: Loss=0.2252, F1=0.9075 (90.75%), Acc=0.9084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Val:   Loss=0.2746, F1=0.9419 (94.19%), Acc=0.8902\n",
            "New best model saved (Val F1=0.9419)\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train: Loss=0.1787, F1=0.9290 (92.90%), Acc=0.9297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Val:   Loss=0.3132, F1=0.9369 (93.69%), Acc=0.8812\n",
            "FINAL TEST EVALUATION\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " FINAL TEST RESULTS\n",
            "----------------------------------------------------------------------\n",
            " Accuracy:  0.8902 (89.03%)\n",
            " Precision: 1.0000 (100.00%)\n",
            " Recall:    0.8902 (89.03%)\n",
            " F1 Score:  0.9419 (94.19%)\n",
            " Excellent!\n",
            "\n",
            "Best model saved to: best_model_s140_bertweet.pt\n",
            "Model used: vinai/bertweet-large\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# 1. INSTALL & IMPORTS\n",
        "\n",
        "print(\"STEP 1: INSTALLING / IMPORTING PACKAGES\")\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Enable HuggingFace tokenizers parallelism for speed\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "\n",
        "# Install core packages (comment out if already installed)\n",
        "subprocess.check_call([\n",
        "    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
        "    \"transformers\", \"sentencepiece\", \"scikit-learn\", \"emoji==0.6.0\"\n",
        "])\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    get_cosine_schedule_with_warmup\n",
        ")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Mixed precision\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "\n",
        "# 2. CONFIG & SEED\n",
        "CONFIG = {\n",
        "    # Models\n",
        "    \"model_name\": \"vinai/bertweet-large\",   # Twitter-optimized model\n",
        "    \"fallback_model\": \"roberta-large\",\n",
        "\n",
        "    # Data\n",
        "    \"data_path\": \"training.1600000.processed.noemoticon.csv\",\n",
        "    \"sample_size\": None, #used up whole available data for training as we need variety of samples\n",
        "    \"max_len\": 128,\n",
        "\n",
        "    # Training\n",
        "    \"batch_size\": 32,\n",
        "    \"gradient_accumulation_steps\": 2,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"epochs\": 3,\n",
        "    \"warmup_ratio\": 0.1,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "\n",
        "    # Dataloader\n",
        "    \"num_workers\": 8,\n",
        "\n",
        "    # Misc\n",
        "    \"seed\": 42,\n",
        "    \"use_fp16\": True\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    # For speed on 5090, allow fast kernels\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "set_seed(CONFIG[\"seed\"])\n",
        "\n",
        "# 3. CLEANING TEXT\n",
        "\n",
        "NEGATION_WORDS = [r\"\\bnot\\b\", r\"\\bnever\\b\", r\"\\bno\\b\"]\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
        "\n",
        "    # Normalize mentions\n",
        "    text = re.sub(r\"@\\w+\", \"@user\", text)\n",
        "\n",
        "    # Remove '#' but keep the word\n",
        "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)\n",
        "\n",
        "    # Normalize repeated characters (3+ -> 2)\n",
        "    # soooo -> soo, niiiice -> niice\n",
        "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)\n",
        "\n",
        "    # Highlight negations\n",
        "    text = re.sub(r\"\\bnot\\b\", \"NOT_\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\bnever\\b\", \"NEVER_\", text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r\"\\bno\\b\", \"NO_\", text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Collapse multiple spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# 4. LOAD & PREPARE DATA\n",
        "print(\"STEP 2: LOADING SENTIMENT140 DATASET\")\n",
        "cols = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "df = pd.read_csv(CONFIG[\"data_path\"], encoding=\"latin-1\", names=cols, header=None)\n",
        "print(f\"Total tweets in raw file: {len(df):,}\")\n",
        "# Map labels: {0, 4} -> {0: negative, 1: positive}\n",
        "df[\"target\"] = df[\"target\"].map({0: 0, 4: 1})\n",
        "\n",
        "# Drop NAs in text just in case\n",
        "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
        "\n",
        "print(\"Applying light cleaning...\")\n",
        "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
        "df = df[df[\"text_clean\"].str.len() > 0].reset_index(drop=True)\n",
        "\n",
        "print(f\"After cleaning: {len(df):,} tweets\")\n",
        "\n",
        "# Sample a subset (dataset is roughly balanced already)\n",
        "if CONFIG[\"sample_size\"] is not None and CONFIG[\"sample_size\"] < len(df):\n",
        "    df_sampled = df.sample(\n",
        "        n=CONFIG[\"sample_size\"],\n",
        "        random_state=CONFIG[\"seed\"]\n",
        "    ).reset_index(drop=True)\n",
        "else:\n",
        "    df_sampled = df.copy()\n",
        "\n",
        "print(f\"\\nUsing {len(df_sampled):,} tweets for training/validation/testing\")\n",
        "\n",
        "# Train / Val / Test split: 90 / 5 / 5  (4k val, 4k test)\n",
        "train_end = len(df_sampled) - 8000\n",
        "val_end = train_end + 4000\n",
        "# last 4k is test\n",
        "\n",
        "train_df = df_sampled.iloc[:train_end].reset_index(drop=True)\n",
        "val_df   = df_sampled.iloc[train_end:val_end].reset_index(drop=True)\n",
        "test_df  = df_sampled.iloc[val_end:].reset_index(drop=True)\n",
        "\n",
        "print(\"\\nDataset splits BEFORE augmentation:\")\n",
        "print(f\"  Train: {len(train_df):,}\")\n",
        "print(f\"  Val:   {len(val_df):,}\")\n",
        "print(f\"  Test:  {len(test_df):,}\")\n",
        "\n",
        "\n",
        "# 5. TARGETED DATA AUGMENTATION\n",
        "\n",
        "POSITIVE_WORDS = [\n",
        "    \"good\", \"great\", \"awesome\", \"amazing\", \"love\",\n",
        "    \"like\", \"happy\", \"fantastic\", \"excellent\", \"cool\",\n",
        "    \"nice\", \"fun\", \"enjoy\"\n",
        "]\n",
        "\n",
        "NEGATIVE_WORDS = [\n",
        "    \"bad\", \"terrible\", \"awful\", \"hate\", \"sad\",\n",
        "    \"horrible\", \"worst\", \"sucks\", \"ugly\", \"annoying\"\n",
        "]\n",
        "\n",
        "def augment_negation_examples(df, max_pos_aug=8000, max_neg_aug=8000):\n",
        "    \"\"\"\n",
        "    Creates synthetic negation-based contrastive examples:\n",
        "      - For positive tweets with positive words -> add a \"NOT_\" version labeled negative\n",
        "      - For negative tweets with negative words -> add a \"NOT_\" version labeled positive\n",
        "    Limits to ~max_pos_aug + max_neg_aug synthetic samples.\n",
        "    \"\"\"\n",
        "    aug_rows = []\n",
        "\n",
        "    # Positive -> create negative via NOT_\n",
        "    pos_df = df[df[\"target\"] == 1].copy()\n",
        "    pos_candidates = pos_df[pos_df[\"text_clean\"].str.contains(\"|\".join(POSITIVE_WORDS), case=False, na=False)]\n",
        "    pos_candidates = pos_candidates.sample(\n",
        "        n=min(max_pos_aug, len(pos_candidates)),\n",
        "        random_state=CONFIG[\"seed\"]\n",
        "    )\n",
        "\n",
        "    for _, row in pos_candidates.iterrows():\n",
        "        txt = row[\"text_clean\"]\n",
        "        # replace first positive word with \"NOT_...\"\n",
        "        for w in POSITIVE_WORDS:\n",
        "            pattern = re.compile(rf\"\\b{re.escape(w)}\\b\", flags=re.IGNORECASE)\n",
        "            if pattern.search(txt):\n",
        "                new_txt = pattern.sub(\"NOT_\" + w, txt, count=1)\n",
        "                new_txt = clean_text(new_txt)\n",
        "                if len(new_txt) > 0:\n",
        "                    aug_rows.append({\"text_clean\": new_txt, \"target\": 0})\n",
        "                break\n",
        "\n",
        "    # Negative -> create positive via NOT_\n",
        "    neg_df = df[df[\"target\"] == 0].copy()\n",
        "    neg_candidates = neg_df[neg_df[\"text_clean\"].str.contains(\"|\".join(NEGATIVE_WORDS), case=False, na=False)]\n",
        "    neg_candidates = neg_candidates.sample(\n",
        "        n=min(max_neg_aug, len(neg_candidates)),\n",
        "        random_state=CONFIG[\"seed\"]\n",
        "    )\n",
        "\n",
        "    for _, row in neg_candidates.iterrows():\n",
        "        txt = row[\"text_clean\"]\n",
        "        for w in NEGATIVE_WORDS:\n",
        "            pattern = re.compile(rf\"\\b{re.escape(w)}\\b\", flags=re.IGNORECASE)\n",
        "            if pattern.search(txt):\n",
        "                new_txt = pattern.sub(\"NOT_\" + w, txt, count=1)\n",
        "                new_txt = clean_text(new_txt)\n",
        "                if len(new_txt) > 0:\n",
        "                    aug_rows.append({\"text_clean\": new_txt, \"target\": 1})\n",
        "                break\n",
        "\n",
        "    aug_df = pd.DataFrame(aug_rows)\n",
        "    if len(aug_df) > 0:\n",
        "        print(f\"\\n[Augmentation] Negation-based synthetic examples added: {len(aug_df):,}\")\n",
        "        df_out = pd.concat(\n",
        "            [df[[\"text_clean\", \"target\"]], aug_df],\n",
        "            ignore_index=True\n",
        "        ).sample(frac=1.0, random_state=CONFIG[\"seed\"]).reset_index(drop=True)\n",
        "    else:\n",
        "        df_out = df[[\"text_clean\", \"target\"]].copy()\n",
        "\n",
        "    return df_out\n",
        "\n",
        "def add_sarcasm_examples():\n",
        "    \"\"\"\n",
        "    Adds a small set of synthetic sarcastic negative tweets,\n",
        "    addressing common error pattern: sarcastic but negative sentiment.\n",
        "    \"\"\"\n",
        "    texts = [\n",
        "        \"Yeah right, exactly what I needed today\",\n",
        "        \"Great, just great... NOT_ happy at all\",\n",
        "        \"Love when everything goes wrong, totally awesome\",\n",
        "        \"Perfect timing, as always... could not be more thrilled\",\n",
        "        \"Best day ever... NO_ joke\",\n",
        "    ]\n",
        "    rows = []\n",
        "    for t in texts:\n",
        "        rows.append({\n",
        "            \"text_clean\": clean_text(t),\n",
        "            \"target\": 0  # negative\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "print(\"\\nApplying targeted augmentation on TRAIN set only...\")\n",
        "\n",
        "# Start from original train_df columns\n",
        "train_aug = train_df[[\"text_clean\", \"target\"]].copy()\n",
        "\n",
        "# 1) Negation-based augmentation\n",
        "train_aug = augment_negation_examples(train_aug, max_pos_aug=8000, max_neg_aug=8000)\n",
        "\n",
        "# 2) Sarcasm augmentation\n",
        "sarcasm_df = add_sarcasm_examples()\n",
        "train_aug = pd.concat([train_aug, sarcasm_df], ignore_index=True)\n",
        "train_aug = train_aug.sample(frac=1.0, random_state=CONFIG[\"seed\"]).reset_index(drop=True)\n",
        "\n",
        "print(f\"Final TRAIN size after augmentation: {len(train_aug):,}\")\n",
        "\n",
        "# For val/test we use original split, no augmentation\n",
        "val_aug = val_df[[\"text_clean\", \"target\"]].copy()\n",
        "test_aug = test_df[[\"text_clean\", \"target\"]].copy()\n",
        "\n",
        "print(\"\\nDataset splits AFTER augmentation:\")\n",
        "print(f\"  Train: {len(train_aug):,}\")\n",
        "print(f\"  Val:   {len(val_aug):,}\")\n",
        "print(f\"  Test:  {len(test_aug):,}\")\n",
        "\n",
        "\n",
        "# 6. DATASET CLASS\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = list(texts)\n",
        "        self.labels = list(labels)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text  = str(self.texts[idx])\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# 7. LOAD TOKENIZER & MODEL (BERTweet)\n",
        "print(f\"STEP 3: LOADING MODEL: {CONFIG['model_name']}\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"model_name\"], use_fast=False)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        CONFIG[\"model_name\"],\n",
        "        num_labels=2\n",
        "    ).to(device)\n",
        "    print(f\"✓ Loaded model: {CONFIG['model_name']}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading {CONFIG['model_name']}: {e}\")\n",
        "    print(f\"Falling back to {CONFIG['fallback_model']}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CONFIG[\"fallback_model\"])\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        CONFIG[\"fallback_model\"],\n",
        "        num_labels=2\n",
        "    ).to(device)\n",
        "    CONFIG[\"model_name\"] = CONFIG[\"fallback_model\"]\n",
        "    print(f\"✓ Loaded fallback model: {CONFIG['model_name']}\")\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model parameters: {total_params:,}\")\n",
        "\n",
        "# Mixed precision scaler\n",
        "scaler = GradScaler(enabled=CONFIG[\"use_fp16\"])\n",
        "\n",
        "# 8. DATALOADERS\n",
        "\n",
        "print(\"\\nCreating datasets & dataloaders...\")\n",
        "train_dataset = SentimentDataset(\n",
        "    train_aug[\"text_clean\"].values,\n",
        "    train_aug[\"target\"].values,\n",
        "    tokenizer,\n",
        "    max_len=CONFIG[\"max_len\"]\n",
        ")\n",
        "val_dataset = SentimentDataset(\n",
        "    val_aug[\"text_clean\"].values,\n",
        "    val_aug[\"target\"].values,\n",
        "    tokenizer,\n",
        "    max_len=CONFIG[\"max_len\"]\n",
        ")\n",
        "test_dataset = SentimentDataset(\n",
        "    test_aug[\"text_clean\"].values,\n",
        "    test_aug[\"target\"].values,\n",
        "    tokenizer,\n",
        "    max_len=CONFIG[\"max_len\"]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=CONFIG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    num_workers=CONFIG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    num_workers=CONFIG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "# 9. OPTIMIZER & SCHEDULER\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=CONFIG[\"learning_rate\"],\n",
        "    weight_decay=CONFIG[\"weight_decay\"]\n",
        ")\n",
        "\n",
        "num_training_steps = (\n",
        "    len(train_loader)\n",
        "    * CONFIG[\"epochs\"]\n",
        "    // CONFIG[\"gradient_accumulation_steps\"]\n",
        ")\n",
        "num_warmup_steps = int(CONFIG[\"warmup_ratio\"] * num_training_steps)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "print(\"\\nTraining configuration:\")\n",
        "print(f\"  Steps:  {num_training_steps:,}\")\n",
        "print(f\"  Warmup: {num_warmup_steps:,}\")\n",
        "print(f\"  Epochs: {CONFIG['epochs']}\")\n",
        "print(f\"  LR:     {CONFIG['learning_rate']}\")\n",
        "print(f\"  Batch:  {CONFIG['batch_size']} (x{CONFIG['gradient_accumulation_steps']} accum)\")\n",
        "\n",
        "\n",
        "# 10. TRAINING & EVAL FUNCTIONS\n",
        "\n",
        "def train_one_epoch(\n",
        "    model,\n",
        "    dataloader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    device,\n",
        "    scaler,\n",
        "    accumulation_steps=1,\n",
        "    use_fp16=True\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    preds_all = []\n",
        "    labels_all = []\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    progress = tqdm(dataloader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for step, batch in enumerate(progress):\n",
        "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "        labels = batch[\"labels\"].to(device, non_blocking=True)\n",
        "\n",
        "        with autocast(enabled=use_fp16):\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            loss = outputs.loss / accumulation_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), CONFIG[\"max_grad_norm\"])\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "            preds_all.extend(preds.cpu().numpy())\n",
        "            labels_all.extend(labels.cpu().numpy())\n",
        "\n",
        "        progress.set_postfix({\n",
        "            \"loss\": f\"{loss.item() * accumulation_steps:.4f}\",\n",
        "            \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
        "        })\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    f1 = f1_score(labels_all, preds_all, average=\"binary\")\n",
        "    acc = accuracy_score(labels_all, preds_all)\n",
        "    return avg_loss, f1, acc\n",
        "\n",
        "def evaluate(model, dataloader, device, use_fp16=True):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    preds_all = []\n",
        "    labels_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
        "            labels = batch[\"labels\"].to(device, non_blocking=True)\n",
        "\n",
        "            with autocast(enabled=use_fp16):\n",
        "                outputs = model(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    labels=labels\n",
        "                )\n",
        "                loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            preds_all.extend(preds.cpu().numpy())\n",
        "            labels_all.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    acc = accuracy_score(labels_all, preds_all)\n",
        "    prec = precision_score(labels_all, preds_all, average=\"binary\")\n",
        "    rec = recall_score(labels_all, preds_all, average=\"binary\")\n",
        "    f1 = f1_score(labels_all, preds_all, average=\"binary\")\n",
        "\n",
        "    return {\n",
        "        \"loss\": avg_loss,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "# 11. TRAINING LOOP\n",
        "\n",
        "print(\"STEP 4: TRAINING\")\n",
        "\n",
        "best_val_f1 = 0.0\n",
        "history = {\"train_loss\": [], \"train_f1\": [], \"val_f1\": []}\n",
        "best_model_path = \"best_model_s140_bertweet.pt\"\n",
        "\n",
        "for epoch in range(CONFIG[\"epochs\"]):\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{CONFIG['epochs']}\")\n",
        "    train_loss, train_f1, train_acc = train_one_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        device,\n",
        "        scaler,\n",
        "        accumulation_steps=CONFIG[\"gradient_accumulation_steps\"],\n",
        "        use_fp16=CONFIG[\"use_fp16\"]\n",
        "    )\n",
        "\n",
        "    print(f\" Train: Loss={train_loss:.4f}, F1={train_f1:.4f} ({train_f1*100:.2f}%), \"\n",
        "          f\"Acc={train_acc:.4f}\")\n",
        "\n",
        "    history[\"train_loss\"].append(train_loss)\n",
        "    history[\"train_f1\"].append(train_f1)\n",
        "\n",
        "    val_metrics = evaluate(\n",
        "        model,\n",
        "        val_loader,\n",
        "        device,\n",
        "        use_fp16=CONFIG[\"use_fp16\"]\n",
        "    )\n",
        "    val_f1 = val_metrics[\"f1\"]\n",
        "    history[\"val_f1\"].append(val_f1)\n",
        "\n",
        "    print(f\" Val:   Loss={val_metrics['loss']:.4f}, \"\n",
        "          f\"F1={val_f1:.4f} ({val_f1*100:.2f}%), \"\n",
        "          f\"Acc={val_metrics['accuracy']:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"New best model saved (Val F1={best_val_f1:.4f})\")\n",
        "\n",
        "\n",
        "# 12. FINAL TEST EVALUATION\n",
        "\n",
        "print(\"FINAL TEST EVALUATION\")\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "\n",
        "test_metrics = evaluate(\n",
        "    model,\n",
        "    test_loader,\n",
        "    device,\n",
        "    use_fp16=CONFIG[\"use_fp16\"]\n",
        ")\n",
        "\n",
        "print(\"\\n FINAL TEST RESULTS\")\n",
        "print(\"-\" * 70)\n",
        "print(f\" Accuracy:  {test_metrics['accuracy']:.4f} ({test_metrics['accuracy']*100:.2f}%)\")\n",
        "print(f\" Precision: {test_metrics['precision']:.4f} ({test_metrics['precision']*100:.2f}%)\")\n",
        "print(f\" Recall:    {test_metrics['recall']:.4f} ({test_metrics['recall']*100:.2f}%)\")\n",
        "print(f\" F1 Score:  {test_metrics['f1']:.4f} ({test_metrics['f1']*100:.2f}%)\")\n",
        "\n",
        "f1_pct = test_metrics[\"f1\"] * 100\n",
        "if f1_pct >= 96:\n",
        "    bonus = 6\n",
        "    status = \"MAXIMUM F1 score ACHIEVED!\"\n",
        "elif f1_pct >= 93:\n",
        "    bonus = 4\n",
        "    status = \"Excellent\"\n",
        "elif f1_pct >= 90:\n",
        "    bonus = 2\n",
        "    status = \"Good job\"\n",
        "else:\n",
        "    bonus = 0\n",
        "    status = \"Below target\"\n",
        "\n",
        "\n",
        "print(f\" {status}\")\n",
        "print(f\"\\nBest model saved to: {best_model_path}\")\n",
        "print(f\"Model used: {CONFIG['model_name']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. THRESHOLD OPTIMIZATION + FINAL TEST EVALUATION\n",
        "\n",
        "print(\"THRESHOLD OPTIMIZATION ON VALIDATION SET\")\n",
        "\n",
        "model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "val_probs = []\n",
        "val_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "        with autocast(enabled=CONFIG[\"use_fp16\"]):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        probs = torch.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "        val_probs.extend(probs)\n",
        "        val_labels.extend(labels)\n",
        "\n",
        "val_probs = np.array(val_probs)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "\n",
        "print(\"\\nSearching for best threshold...\")\n",
        "for t in np.arange(0.10, 0.91, 0.01):\n",
        "    preds = (val_probs >= t).astype(int)\n",
        "    f1 = f1_score(val_labels, preds)\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "print(f\"\\nBest Validation Threshold = {best_thresh:.2f}\")\n",
        "print(f\"Best Validation F1 = {best_f1:.4f} ({best_f1*100:.2f}%)\")\n",
        "\n",
        "# 13. FINAL TEST EVALUATION USING OPTIMAL THRESHOLD\n",
        "\n",
        "print(\"FINAL TEST EVALUATION (THRESHOLD)\")\n",
        "\n",
        "test_probs = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].cpu().numpy()\n",
        "\n",
        "        with autocast(enabled=CONFIG[\"use_fp16\"]):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        probs = torch.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
        "        test_probs.extend(probs)\n",
        "        test_labels.extend(labels)\n",
        "\n",
        "test_probs = np.array(test_probs)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "test_preds = (test_probs >= best_thresh).astype(int)\n",
        "\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "test_precision = precision_score(test_labels, test_preds)\n",
        "test_recall = recall_score(test_labels, test_preds)\n",
        "test_f1 = f1_score(test_labels, test_preds)\n",
        "\n",
        "print(\"\\n FINAL TEST RESULTS (WITH OPTIMIZED THRESHOLD)\")\n",
        "print(\"-\" * 70)\n",
        "print(f\" Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "print(f\" Precision: {test_precision:.4f} ({test_precision*100:.2f}%)\")\n",
        "print(f\" Recall:    {test_recall:.4f} ({test_recall*100:.2f}%)\")\n",
        "print(f\" F1 Score:  {test_f1:.4f} ({test_f1*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nOptimal threshold applied:\", best_thresh)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyCkkCIDIJcM",
        "outputId": "2f625e7e-2c49-4218-d0bb-f83d214274ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THRESHOLD OPTIMIZATION ON VALIDATION SET\n",
            "\n",
            "Searching for best threshold...\n",
            "\n",
            "Best Validation Threshold = 0.10\n",
            "Best Validation F1 = 0.9848 (98.48%)\n",
            "FINAL TEST EVALUATION (THRESHOLD)\n",
            "\n",
            " FINAL TEST RESULTS (WITH OPTIMIZED THRESHOLD)\n",
            "----------------------------------------------------------------------\n",
            " Accuracy:  0.9685 (96.85%)\n",
            " Precision: 1.0000 (100.00%)\n",
            " Recall:    0.9685 (96.85%)\n",
            " F1 Score:  0.9840 (98.40%)\n",
            "\n",
            "Optimal threshold applied: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" FINAL F1 SCORE With OPTIMIZED CODE\")\n",
        "print(f\" Final F1:  {test_f1:.4f} ({test_f1*100:.2f}%)\")\n",
        "print(f\" Best threshold used: {best_thresh:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWTRdy6_IMFT",
        "outputId": "e1b1f00f-3414-4104-b09b-05efff5dd7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " FINAL F1 SCORE With OPTIMIZED CODE\n",
            " Final F1:  0.9840 (98.40%)\n",
            " Best threshold used: 0.10\n"
          ]
        }
      ]
    }
  ]
}